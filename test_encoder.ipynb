{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.helper import load_checkpoint, init_model\n",
    "from src.datasets.ukbb import make_ukbb\n",
    "from src.models.vision_transformer import vit_custom\n",
    "from src.masks.multiblock import MaskCollator as MBMaskCollator\n",
    "import yaml\n",
    "from src.transforms import make_transforms\n",
    "import pprint\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:making ecg data transforms\n",
      "INFO:root:Initialized UKBB\n",
      "INFO:root:UKBB dataset created\n",
      "INFO:root:Ukbb unsupervised data loader created\n",
      "INFO:root:Initialized UKBB\n",
      "INFO:root:UKBB dataset created\n",
      "INFO:root:Ukbb unsupervised data loader created\n"
     ]
    }
   ],
   "source": [
    "with open(\"configs/configs_vitt.yaml\", 'r') as y_file:\n",
    "        args = yaml.load(y_file, Loader=yaml.FullLoader)\n",
    "        pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "# -- META\n",
    "use_bfloat16 = args['meta']['use_bfloat16']\n",
    "model_name = args['meta']['model_name']\n",
    "load_model = args['meta']['load_checkpoint'] or False\n",
    "r_file = args['meta']['read_checkpoint']\n",
    "copy_data = args['meta']['copy_data']\n",
    "pred_depth = args['meta']['pred_depth']\n",
    "pred_emb_dim = args['meta']['pred_emb_dim']\n",
    "if not torch.cuda.is_available():\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.cuda.set_device(device)\n",
    "\n",
    "# -- DATA\n",
    "rescale_sigma = args['data']['rescale_sigma']\n",
    "ftsurrogate = args['data']['ftsurrogate']\n",
    "jitter = args['data']['jitter']\n",
    "spec_augment = args['data']['spec_augment']\n",
    "time_flip = args['data']['time_flip']\n",
    "sign_flip = args['data']['sign_flip']\n",
    "# --\n",
    "batch_size = args['data']['batch_size']\n",
    "pin_mem = args['data']['pin_mem']\n",
    "num_workers = args['data']['num_workers']\n",
    "root_path = args['data']['root_path']\n",
    "image_folder = args['data']['data_path']\n",
    "val_folder = args['data']['val_path']\n",
    "downstream_train_path = args['data']['downstream_train_path']\n",
    "downstream_val_path = args['data']['downstream_val_path']\n",
    "crop_size = args['data']['crop_size']\n",
    "crop_scale = args['data']['crop_scale']\n",
    "# --\n",
    "\n",
    "# -- MASK\n",
    "allow_overlap = args['mask']['allow_overlap']  # whether to allow overlap b/w context and target blocks\n",
    "patch_size = args['mask']['patch_size']  # patch-size for model training\n",
    "num_enc_masks = args['mask']['num_enc_masks']  # number of context blocks\n",
    "min_keep = args['mask']['min_keep']  # min number of patches in context block\n",
    "enc_mask_scale = args['mask']['enc_mask_scale']  # scale of context blocks\n",
    "num_pred_masks = args['mask']['num_pred_masks']  # number of target blocks\n",
    "pred_mask_scale = args['mask']['pred_mask_scale']  # scale of target blocks\n",
    "aspect_ratio = args['mask']['aspect_ratio']  # aspect ratio of target blocks\n",
    "# --    \n",
    "# -- make data transforms\n",
    "mask_collator = MBMaskCollator(\n",
    "    input_size=crop_size,\n",
    "    patch_size=patch_size,\n",
    "    pred_mask_scale=pred_mask_scale,\n",
    "    enc_mask_scale=enc_mask_scale,\n",
    "    aspect_ratio=aspect_ratio,\n",
    "    nenc=num_enc_masks,\n",
    "    npred=num_pred_masks,\n",
    "    allow_overlap=allow_overlap,\n",
    "    min_keep=min_keep)\n",
    "\n",
    "transform = make_transforms(\n",
    "    crop_resizing=crop_size,\n",
    "    ftsurrogate=ftsurrogate,\n",
    "    jitter=jitter,\n",
    "    rescale_sigma=rescale_sigma,\n",
    "    time_flip=time_flip,\n",
    "    sign_flip=sign_flip,\n",
    "    spec_augment = spec_augment\n",
    "    )\n",
    "\n",
    "_, downstream_train_loader,_ = make_ukbb(\n",
    "        transform=None,\n",
    "        batch_size=batch_size,\n",
    "        collator=mask_collator,\n",
    "        pin_mem=pin_mem,\n",
    "        training=True,\n",
    "        num_workers=num_workers,\n",
    "        world_size=1,\n",
    "        rank=0,\n",
    "        root_path=root_path,\n",
    "        data_file=downstream_train_path,\n",
    "        copy_data=False,\n",
    "        drop_last=True\n",
    ")\n",
    "_, downstream_val_loader,_ = make_ukbb(\n",
    "        transform=None,\n",
    "        batch_size=batch_size,\n",
    "        collator=mask_collator,\n",
    "        pin_mem=pin_mem,\n",
    "        training=True,\n",
    "        num_workers=num_workers,\n",
    "        world_size=1,\n",
    "        rank=0,\n",
    "        root_path=root_path,\n",
    "        data_file=downstream_val_path,\n",
    "        copy_data=False,\n",
    "        drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"/vol/aimspace/users/seel/wandb/run-20240206_114842-i17qy14j/files/jepa-latest.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(1, 192, kernel_size=(1, 100), stride=(1, 100))\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder, predictor = init_model(\n",
    "        device=\"cuda:0\",\n",
    "        patch_size=(1,100),\n",
    "        crop_size=(12,500),\n",
    "        pred_depth=1,\n",
    "        pred_emb_dim=96,\n",
    "        model_name=model_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 600, 192])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.pos_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['encoder', 'predictor', 'target_encoder', 'opt', 'scaler', 'epoch', 'loss', 'batch_size', 'world_size', 'lr'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
    "epoch = checkpoint['epoch']\n",
    "pretrained_dict = checkpoint['encoder']\n",
    "checkpoint.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint[\"scaler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pretrained encoder from epoch 200 with msg: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pretrained_dict = {k.replace(\"module.\", \"\"): v for k, v in pretrained_dict.items()}\n",
    "msg = encoder.load_state_dict(pretrained_dict)\n",
    "print(f'loaded pretrained encoder from epoch {epoch} with msg: {msg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in encoder.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,encoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        \n",
    "        self.fc1 = nn.Linear(384, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net(encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:03,  3.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "encoder.eval()\n",
    "encodings_train = torch.tensor([])\n",
    "labels_train = torch.tensor([])\n",
    "encodings_val = torch.tensor([])\n",
    "labels_val = torch.tensor([])\n",
    "\n",
    "for itr, (udata, masks_enc, masks_pred) in tqdm(enumerate(downstream_train_loader)):\n",
    "    def load_imgs():\n",
    "        # -- unsupervised imgs\n",
    "        imgs = udata[0].to(device, non_blocking=True)\n",
    "        labels = udata[1]\n",
    "        \n",
    "        return (imgs, labels)\n",
    "    imgs, labels = load_imgs()\n",
    "    labels_train=torch.cat((labels_train,labels.cpu()), 0)\n",
    "    def forward_target():\n",
    "        with torch.no_grad():\n",
    "            h = encoder(imgs)\n",
    "            h = F.layer_norm(h, (h.size(-1),))  # normalize over feature-dim\n",
    "            return h\n",
    "    # Step 1. Forward\n",
    "    with torch.cuda.amp.autocast(dtype=torch.bfloat16, enabled=False):\n",
    "        h = forward_target() # shape of h: (B,600,768) e.g. B=32\n",
    "        encodings_train = torch.cat((encodings_train,h.detach().cpu()), 0)\n",
    "for itr, (udata, masks_enc, masks_pred) in enumerate(downstream_val_loader):\n",
    "    def load_imgs():\n",
    "        # -- unsupervised imgs\n",
    "        imgs = udata[0].to(device, non_blocking=True)\n",
    "        labels = udata[1]\n",
    "        return (imgs, labels)\n",
    "    imgs, labels = load_imgs()\n",
    "    labels_val=torch.cat((labels_val,labels.cpu()), 0)\n",
    "    def forward_target():\n",
    "        with torch.no_grad():\n",
    "            h = encoder(imgs)\n",
    "            h = F.layer_norm(h, (h.size(-1),))  # normalize over feature-dim\n",
    "            return h\n",
    "    # Step 1. Forward\n",
    "    with torch.cuda.amp.autocast(dtype=torch.bfloat16, enabled=False):\n",
    "        h = forward_target()\n",
    "        \n",
    "        encodings_val=torch.cat((encodings_val,h.detach().cpu()), 0)\n",
    "        \n",
    "encodings_train = encodings_train.mean(dim=1)\n",
    "encodings_val = encodings_val.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6670673076923077 0.7242697408338389 0.6654589371980677\n",
      "0.64453125 0.70257568359375 0.6459143968871596\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000,random_state=0,C=0.001))\n",
    "\n",
    "pipe.fit(\n",
    "    np.asarray(encodings_train), #.reshape(len(encodings_train),-1)\n",
    "    np.asarray(labels_train).flatten())\n",
    "            \n",
    "train_proba = pipe.predict_proba(\n",
    "    np.asarray(encodings_train),  #.reshape(len(encodings_train),-1)\n",
    "    )[:, 1]\n",
    "            \n",
    "train_pred = pipe.predict(\n",
    "    np.asarray(encodings_train),  #.reshape(len(encodings_train),-1)\n",
    "    )\n",
    "            \n",
    "train_acc = accuracy_score(np.asarray(labels_train).flatten(), train_pred)\n",
    "train_auc = roc_auc_score(np.asarray(labels_train).flatten(), train_proba)\n",
    "train_f1 = f1_score(np.asarray(labels_train).flatten(), train_pred)\n",
    "            \n",
    "val_pred = pipe.predict(\n",
    "    np.asarray(encodings_val), #.reshape(len(encodings_val),-1)\n",
    "    )\n",
    "            \n",
    "val_proba = pipe.predict_proba(\n",
    "    np.asarray(encodings_val), #.reshape(len(encodings_val),-1)\n",
    "    )[:, 1]\n",
    "            \n",
    "val_acc = accuracy_score(np.asarray(labels_val).flatten(), val_pred)\n",
    "val_auc = roc_auc_score(np.asarray(labels_val).flatten(), val_proba)\n",
    "val_f1 = f1_score(np.asarray(labels_val).flatten(), val_pred)\n",
    "\n",
    "print(train_acc, train_auc, train_f1)\n",
    "print(val_acc,val_auc,val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "net = net.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 0.004\n",
      "[2,    20] loss: 0.004\n",
      "[3,    20] loss: 0.004\n",
      "[4,    20] loss: 0.004\n",
      "[5,    20] loss: 0.003\n",
      "[6,    20] loss: 0.003\n",
      "[7,    20] loss: 0.003\n",
      "[8,    20] loss: 0.003\n",
      "[9,    20] loss: 0.003\n",
      "[10,    20] loss: 0.003\n",
      "[11,    20] loss: 0.003\n",
      "[12,    20] loss: 0.003\n",
      "[13,    20] loss: 0.003\n",
      "[14,    20] loss: 0.003\n",
      "[15,    20] loss: 0.003\n",
      "[16,    20] loss: 0.003\n",
      "[17,    20] loss: 0.003\n",
      "[18,    20] loss: 0.003\n",
      "[19,    20] loss: 0.003\n",
      "[20,    20] loss: 0.003\n",
      "[21,    20] loss: 0.003\n",
      "[22,    20] loss: 0.003\n",
      "[23,    20] loss: 0.003\n",
      "[24,    20] loss: 0.003\n",
      "[25,    20] loss: 0.003\n",
      "[26,    20] loss: 0.003\n",
      "[27,    20] loss: 0.003\n",
      "[28,    20] loss: 0.003\n",
      "[29,    20] loss: 0.003\n",
      "[30,    20] loss: 0.003\n",
      "[31,    20] loss: 0.003\n",
      "[32,    20] loss: 0.003\n",
      "[33,    20] loss: 0.003\n",
      "[34,    20] loss: 0.003\n",
      "[35,    20] loss: 0.003\n",
      "[36,    20] loss: 0.003\n",
      "[37,    20] loss: 0.003\n",
      "[38,    20] loss: 0.003\n",
      "[39,    20] loss: 0.003\n",
      "[40,    20] loss: 0.003\n",
      "[41,    20] loss: 0.003\n",
      "[42,    20] loss: 0.003\n",
      "[43,    20] loss: 0.003\n",
      "[44,    20] loss: 0.003\n",
      "[45,    20] loss: 0.003\n",
      "[46,    20] loss: 0.003\n",
      "[47,    20] loss: 0.003\n",
      "[48,    20] loss: 0.003\n",
      "[49,    20] loss: 0.003\n",
      "[50,    20] loss: 0.003\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for itr, (udata, masks_enc, masks_pred) in enumerate(downstream_val_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = udata[0].to(device, non_blocking=True), udata[1].float().to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        outputs=outputs.mean(dim=1)\n",
    "        #print(outputs, labels)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if itr % 20 == 19:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {itr + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(downstream_train_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(downstream_val_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sjepa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
